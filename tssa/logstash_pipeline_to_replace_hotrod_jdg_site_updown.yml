input {
  exec {
    command => "/usr/share/logstash/bin/jdgsiteupdown.sh"
    schedule => "*/60 * * * * * UTC"
    codec => multiline {
      pattern => "\n"
      what => "previous"
    }
  }
}

# Filter for site sla

filter {
  grok {
   tag_on_failure => []
   break_on_match => false
   match => [
            "message",  "probe_success\{instance=\"(?<instance>[^\"]+)\",job=\"(?<job>[^\"]+)\"\} (?<ok>\d+) (?<epoch_millis>\d+)"
            ]
  }
  grok {
   tag_on_failure => []
   break_on_match => false
   match => [
            "job",  "[^-]+-[^-]+-[^-]+-[^-]+-(?<org>[^-]+)-",
            "job",  "^(?<job_status>[^-]+)-(?<device_name>.*)-(?<bu_code>\d+)$",
            "instance",  "^\w{2}(?<country_code>.*)SD\-[^:]+(?<interface>\d+):(?<dest_port>\d+)$"
            ]
  }
if "1" in [ok] {
  mutate {
    add_field => { "status" => "On" }

 }
}
else if "0" in [ok] {
  mutate {
    add_field => { "status" => "Off" }

  }
 }
  mutate {
    add_field => { "[@timestamp_logstash]" => "%{[@timestamp]}" }
  }

date {
  match => [ "epoch_millis", "UNIX_MS" ]
  timezone => "Africa/Johannesburg"
  }
#  if [interface] != "0"{
#  drop {}
#  }

mutate {
  convert => [
    "epoch_millis", "integer"
   ]
  }

  aggregate {
    aggregate_maps_path => "/var/lib/logstash/.aggregate_maps_jdg_updown"
    task_id => "%{instance}"
    timeout => 31556952
    inactivity_timeout => 31556952
    code => "
      map['previous_durable_status'] ||= event.get('status')

      event.set('old_status', event.get('status'))
      event.set('previous_status', map['previous_status'])
      if (event.get('status') == 'On')
      map['duration_up1'] ||= 0
      map['duration_up1'] += 1
      event.set('previous_duration', map['duration_up1'])
      else
        map['duration_up1'] = 0
      end
      if (event.get('status') == 'Off')
        map['duration_down1'] ||= 0
        map['duration_down1'] += 1
        event.set('previous_duration', map['duration_down1'])
      else
        map['duration_down1'] = 0
      end
      if (event.get('previous_duration') > 14)
         map['previous_status'] = event.get('status')
      end
      if (event.get('previous_status') == 'On')
      map['duration_up'] ||= 0
      map['duration_up'] += 1
      event.set('duration', map['duration_up'])
      else
        map['duration_up'] = 0
      end
      if (event.get('previous_status') == 'Off')
        map['duration_down'] ||= 0
        map['duration_down'] += 1
        event.set('duration', map['duration_down'])
      else
        map['duration_down'] = 0
      end
    "
  }
if ![previous_status]{
  drop {}
}

fingerprint {
  source => "message"
  target => "[@metadata][fingerprint]"
  method => "MD5"
  key => "sla"
 }

ruby {
  code => "event.set('[@metadata][tsprefix]', event.get('@timestamp').to_i.to_s(16))"
 }

mutate {
  convert => [ 
    "ok", "integer",
    "dest_port", "integer",
    "previous_duration", "integer",
    "duration", "integer",
    "epoch_millis", "integer",
    "interface", "integer"
   ]
 }

mutate {
  remove_field => ["message", "command"]
 }
 if ![job]{
  drop {}
  }
}

# Output to  Elasticsearch cluster

output {
if  [job] and [instance]{
#  stdout{ codec => rubydebug}
  elasticsearch {
    index => "logstash-jdg-updown-site-%{+YYYY.MM.dd}"
    hosts => ["196.9.88.116:9200", "196.9.88.117:9200", "196.9.88.118:9200"]
    document_id => "%{[@metadata][tsprefix]}%{[@metadata][fingerprint]}"
   }
#    influxdb {                                                                                                                                                                                
#      host => "192.168.26.104"                                                                                                                                                                      
#      port => 8086                                                                                                                                                                              
#      ssl => "false"                                                                                                                                                                            
#      db => "logstashJDPsiteSLA"                                                                                                                                                                          
#      codec => "json"                                                                                                                                                                          
#      send_as_tags => ["host", "status", "dest_port", "instance", "org", "businesshours", "job", "country_code", "bu_code", "device_name","SCW", "total_business_hours", "target", "siteName", "job_status" ]                                                                                                                              
#      use_event_fields_for_data_points => true
#      data_pointt
#      exclude_fields => ["@timestamp_logstash", "@timestamp", "@version", "type", "tags", "host"]
#  }
 }
}
